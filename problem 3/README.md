# Problem: Log file Analyzer

Load and parse the given program log file to generate insights on the frequency of warnings, errors and most common error types.

## Statement

You are given a LOG file `sample.log` that was generated by a different Program. It is in a standard format (all lines follow the same formatting) and also each line indicates the severity level of the log (e.g. `INFO`, `WARN`, `ERROR`).

Sample log lines:

```
INFO      2024-11-10 14:26:23 - [tredex_server.rag_impl.pipeline] (pipeline.py:17) Ingesting
WARNING   2024-11-10 14:26:06 - [tredex_server.app.resources.rag.rag_session.session_factory] (session_factory.py:110) No RAG pipeline specified. Loading dummy pipeline.

ERROR     2024-08-23 03:33:59 - [taskiq.receiver.receiver] (receiver.py:281) Exception found while executing function: [Errno 2] No such file or directory: './db/ddl/customer/document_process.sql'
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/taskiq/receiver/receiver.py", line 271, in run_task
    returned = await target_future
               ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/tredex_server/app/resources/document_process/tasks/document_processing.py", line 203, in task_process_documents
    await doc_process.create_tables()
  File "/usr/local/lib/python3.11/site-packages/tredex_server/app/resources/document_process/tasks/document_processing.py", line 73, in create_tables
    await execute_factory_ddl(connection)
  File "/usr/local/lib/python3.11/site-packages/tredex_server/app/resources/document_process/tasks/db_stored_queries.py", line 8, in execute_factory_ddl
    async with aiofiles.open("./db/ddl/customer/document_process.sql", "r") as f:
  File "/usr/local/lib/python3.11/site-packages/aiofiles/base.py", line 98, in __aenter__
    self._obj = await self._coro
                ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/aiofiles/threadpool/__init__.py", line 94, in _open
    f = yield from loop.run_in_executor(executor, cb)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './db/ddl/customer/document_process.sql'
```

Write a Python program / functions to:

1. Load the log data, parse it properly.
    * If any line is malformed, skip it but display something in output about it, don't silently ignore it.
    * Sort the log lines by the log date (as the log is combined from multiple log files but not sequential).

2. Count how many `ERROR`, `INFO`, `DEBUG`, etc. entries there are.

3. List all timestamps of `ERROR` messages

4. Print the most frequent log level.

5. Are there any messages that repeatedly occur (i.e. duplicates)? How do you handle this?

6. How many times did the application start?

7. Average Time Between Logs: Compute the average time delta (in seconds or minutes) between consecutive log entries.

8. Detect Bursts of Errors:
    * Identify if more than N `ERROR` logs occurred within any 5-minute sliding window (e.g., N=3, so 3 consecutive lines of `ERROR`).
    * Print the time ranges of such bursts.
    * Do the same for `WARNING` logs.


Log format used:
`%(levelname)-9s %(asctime)s - [%(name)s] (%(filename)s:%(lineno)d) %(message)s`
